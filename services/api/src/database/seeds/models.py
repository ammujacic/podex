"""Default LLM models seed data.

These models use OpenRouter as the provider. Model IDs match OpenRouter's API.
Pricing is approximate - verify against https://openrouter.ai/models for current rates.
"""

DEFAULT_MODELS = [
    # ====================
    # ANTHROPIC CLAUDE MODELS
    # ====================
    {
        "model_id": "anthropic/claude-sonnet-4.5",
        "display_name": "Claude Sonnet 4.5",
        "provider": "openrouter",
        "family": "anthropic",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 15.0,
        "is_enabled": True,
        "is_default": True,  # Platform default
        "sort_order": 10,
        "is_featured": True,
        "display_order": 10,
        "categories": ["reasoning", "code", "vision"],
        "short_description": "Best balance of speed, quality, and cost",
        "model_metadata": {
            "description": "Anthropic's most balanced model for coding and analysis",
            "good_for": ["Coding", "Agentic Tasks", "Analysis", "Vision"],
        },
    },
    {
        "model_id": "anthropic/claude-opus-4.5",
        "display_name": "Claude Opus 4.5",
        "provider": "openrouter",
        "family": "anthropic",
        "cost_tier": "premium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 15.0,
        "output_cost_per_million": 75.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 20,
        "is_featured": True,
        "display_order": 20,
        "categories": ["reasoning", "code", "vision"],
        "short_description": "Most capable model for complex reasoning",
        "model_metadata": {
            "description": "Anthropic's most powerful model for complex tasks",
            "good_for": ["Complex Coding", "Architecture", "Deep Analysis"],
        },
    },
    {
        "model_id": "anthropic/claude-haiku-4.5",
        "display_name": "Claude Haiku 4.5",
        "provider": "openrouter",
        "family": "anthropic",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.25,
        "output_cost_per_million": 1.25,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 30,
        "is_featured": True,
        "display_order": 30,
        "categories": ["fast", "budget"],
        "short_description": "Fast and affordable for simple tasks",
        "model_metadata": {
            "description": "Anthropic's fastest and most affordable model",
            "good_for": ["Quick Tasks", "Chat", "Efficient Agents"],
        },
    },
    # ====================
    # OPENAI MODELS
    # ====================
    {
        "model_id": "openai/gpt-4o",
        "display_name": "GPT-4o",
        "provider": "openrouter",
        "family": "openai",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 2.5,
        "output_cost_per_million": 10.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 40,
        "is_featured": True,
        "display_order": 40,
        "categories": ["reasoning", "code", "vision"],
        "short_description": "OpenAI's flagship multimodal model",
        "model_metadata": {
            "description": "OpenAI's most capable general-purpose model",
            "good_for": ["Multimodal", "Coding", "Vision", "Analysis"],
        },
    },
    {
        "model_id": "openai/gpt-4o-mini",
        "display_name": "GPT-4o Mini",
        "provider": "openrouter",
        "family": "openai",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 0.15,
        "output_cost_per_million": 0.6,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 50,
        "is_featured": True,
        "display_order": 50,
        "categories": ["fast", "budget", "vision"],
        "short_description": "Fast and affordable GPT-4 variant",
        "model_metadata": {
            "description": "Cost-effective GPT-4 for everyday tasks",
            "good_for": ["Fast Tasks", "Budget", "Chat", "Vision"],
        },
    },
    {
        "model_id": "openai/o1",
        "display_name": "o1",
        "provider": "openrouter",
        "family": "openai",
        "cost_tier": "premium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_million": 15.0,
        "output_cost_per_million": 60.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 60,
        "is_featured": True,
        "display_order": 60,
        "categories": ["reasoning"],
        "short_description": "Advanced reasoning with chain-of-thought",
        "model_metadata": {
            "description": "OpenAI's reasoning model with extended thinking",
            "good_for": ["Complex Reasoning", "Math", "Science", "Coding"],
        },
    },
    {
        "model_id": "openai/o1-mini",
        "display_name": "o1 Mini",
        "provider": "openrouter",
        "family": "openai",
        "cost_tier": "medium",
        "capabilities": {
            "vision": False,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 12.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 70,
        "is_featured": True,
        "display_order": 70,
        "categories": ["reasoning", "code"],
        "short_description": "Fast reasoning for coding and math",
        "model_metadata": {
            "description": "Efficient reasoning model optimized for STEM",
            "good_for": ["Coding", "Math", "Fast Reasoning"],
        },
    },
    # ====================
    # GOOGLE GEMINI MODELS
    # ====================
    {
        "model_id": "google/gemini-2.0-flash-001",
        "display_name": "Gemini 2.0 Flash",
        "provider": "openrouter",
        "family": "google",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.1,
        "output_cost_per_million": 0.4,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 80,
        "is_featured": True,
        "display_order": 80,
        "categories": ["fast", "large_context", "vision"],
        "short_description": "Google's fastest model with 1M context",
        "model_metadata": {
            "description": "Ultra-fast with massive context window",
            "good_for": ["Fast Tasks", "Long Documents", "Multimodal"],
        },
    },
    {
        "model_id": "google/gemini-2.5-pro-preview",
        "display_name": "Gemini 2.5 Pro",
        "provider": "openrouter",
        "family": "google",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 1000000,
        "max_output_tokens": 65536,
        "input_cost_per_million": 1.25,
        "output_cost_per_million": 10.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 90,
        "is_featured": True,
        "display_order": 90,
        "categories": ["reasoning", "large_context", "code", "vision"],
        "short_description": "Google's flagship model for complex tasks",
        "model_metadata": {
            "description": "Most capable Gemini with thinking capabilities",
            "good_for": ["Complex Reasoning", "Coding", "Long Context"],
        },
    },
    {
        "model_id": "google/gemini-pro-1.5",
        "display_name": "Gemini 1.5 Pro",
        "provider": "openrouter",
        "family": "google",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 2000000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 1.25,
        "output_cost_per_million": 5.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 100,
        "is_featured": True,
        "display_order": 100,
        "categories": ["large_context", "vision"],
        "short_description": "2M context for massive documents",
        "model_metadata": {
            "description": "Largest context window available",
            "good_for": ["Massive Documents", "Video", "Codebase Analysis"],
        },
    },
    # ====================
    # META LLAMA MODELS
    # ====================
    {
        "model_id": "meta-llama/llama-3.3-70b-instruct",
        "display_name": "Llama 3.3 70B",
        "provider": "openrouter",
        "family": "meta",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.18,
        "output_cost_per_million": 0.18,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 110,
        "is_featured": True,
        "display_order": 110,
        "categories": ["code", "budget"],
        "short_description": "Latest Llama, excellent for coding",
        "model_metadata": {
            "description": "Meta's newest open model with strong coding",
            "good_for": ["Coding", "General Tasks", "Open Source"],
        },
    },
    {
        "model_id": "meta-llama/llama-3.1-405b-instruct",
        "display_name": "Llama 3.1 405B",
        "provider": "openrouter",
        "family": "meta",
        "cost_tier": "medium",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 3.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 120,
        "is_featured": True,
        "display_order": 120,
        "categories": ["reasoning", "code"],
        "short_description": "Largest open model available",
        "model_metadata": {
            "description": "Most powerful open-source model",
            "good_for": ["Complex Tasks", "Coding", "Analysis"],
        },
    },
    {
        "model_id": "meta-llama/llama-3.1-8b-instruct",
        "display_name": "Llama 3.1 8B",
        "provider": "openrouter",
        "family": "meta",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.06,
        "output_cost_per_million": 0.06,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 130,
        "is_featured": True,
        "display_order": 130,
        "categories": ["fast", "budget"],
        "short_description": "Fast and efficient small model",
        "model_metadata": {
            "description": "Lightweight model for simple tasks",
            "good_for": ["Quick Tasks", "Budget", "Efficient Agents"],
        },
    },
    # ====================
    # DEEPSEEK MODELS
    # ====================
    {
        "model_id": "deepseek/deepseek-r1",
        "display_name": "DeepSeek R1",
        "provider": "openrouter",
        "family": "deepseek",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 64000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.55,
        "output_cost_per_million": 2.19,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 140,
        "is_featured": True,
        "display_order": 140,
        "categories": ["reasoning", "code", "budget"],
        "short_description": "Open reasoning model rivaling o1",
        "model_metadata": {
            "description": "DeepSeek's reasoning model with chain-of-thought",
            "good_for": ["Reasoning", "Math", "Coding", "Science"],
        },
    },
    {
        "model_id": "deepseek/deepseek-chat",
        "display_name": "DeepSeek V3",
        "provider": "openrouter",
        "family": "deepseek",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 64000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.14,
        "output_cost_per_million": 0.28,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 150,
        "is_featured": True,
        "display_order": 150,
        "categories": ["code", "budget"],
        "short_description": "Excellent coding at very low cost",
        "model_metadata": {
            "description": "High-quality coding model at budget prices",
            "good_for": ["Coding", "General Tasks", "Budget"],
        },
    },
    # ====================
    # MISTRAL MODELS
    # ====================
    {
        "model_id": "mistralai/mistral-large-2411",
        "display_name": "Mistral Large",
        "provider": "openrouter",
        "family": "mistral",
        "cost_tier": "medium",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 2.0,
        "output_cost_per_million": 6.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 160,
        "is_featured": True,
        "display_order": 160,
        "categories": ["reasoning", "code"],
        "short_description": "Mistral's flagship model",
        "model_metadata": {
            "description": "Most capable Mistral model",
            "good_for": ["Coding", "Analysis", "Multilingual"],
        },
    },
    {
        "model_id": "mistralai/mistral-small-2503",
        "display_name": "Mistral Small",
        "provider": "openrouter",
        "family": "mistral",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 32000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.1,
        "output_cost_per_million": 0.3,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 170,
        "is_featured": True,
        "display_order": 170,
        "categories": ["fast", "budget"],
        "short_description": "Fast and efficient Mistral",
        "model_metadata": {
            "description": "Efficient model for everyday tasks",
            "good_for": ["Fast Tasks", "Budget", "Multilingual"],
        },
    },
    {
        "model_id": "mistralai/codestral-2501",
        "display_name": "Codestral",
        "provider": "openrouter",
        "family": "mistral",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 256000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.3,
        "output_cost_per_million": 0.9,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 180,
        "is_featured": True,
        "display_order": 180,
        "categories": ["code", "large_context"],
        "short_description": "Specialized coding model",
        "model_metadata": {
            "description": "Mistral's dedicated coding model",
            "good_for": ["Code Generation", "Code Review", "Refactoring"],
        },
    },
    # ====================
    # QWEN MODELS
    # ====================
    {
        "model_id": "qwen/qwen-2.5-72b-instruct",
        "display_name": "Qwen 2.5 72B",
        "provider": "openrouter",
        "family": "qwen",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.35,
        "output_cost_per_million": 0.4,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 190,
        "is_featured": True,
        "display_order": 190,
        "categories": ["code", "budget"],
        "short_description": "Strong multilingual and coding",
        "model_metadata": {
            "description": "Alibaba's flagship open model",
            "good_for": ["Coding", "Multilingual", "General Tasks"],
        },
    },
    {
        "model_id": "qwen/qwen-2.5-coder-32b-instruct",
        "display_name": "Qwen 2.5 Coder 32B",
        "provider": "openrouter",
        "family": "qwen",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 32000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.18,
        "output_cost_per_million": 0.18,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 200,
        "is_featured": True,
        "display_order": 200,
        "categories": ["code", "budget"],
        "short_description": "Specialized coding model",
        "model_metadata": {
            "description": "Qwen's dedicated coding model",
            "good_for": ["Code Generation", "Debugging", "Refactoring"],
        },
    },
    {
        "model_id": "qwen/qwq-32b",
        "display_name": "QwQ 32B",
        "provider": "openrouter",
        "family": "qwen",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 32000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.12,
        "output_cost_per_million": 0.18,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 210,
        "is_featured": True,
        "display_order": 210,
        "categories": ["reasoning", "budget"],
        "short_description": "Open reasoning model",
        "model_metadata": {
            "description": "Qwen's reasoning model with thinking",
            "good_for": ["Reasoning", "Math", "Problem Solving"],
        },
    },
    # ====================
    # COHERE MODELS
    # ====================
    {
        "model_id": "cohere/command-r-plus-08-2024",
        "display_name": "Command R+",
        "provider": "openrouter",
        "family": "cohere",
        "cost_tier": "medium",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 2.5,
        "output_cost_per_million": 10.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 220,
        "is_featured": True,
        "display_order": 220,
        "categories": ["reasoning", "large_context"],
        "short_description": "Enterprise-grade with RAG focus",
        "model_metadata": {
            "description": "Cohere's flagship for enterprise tasks",
            "good_for": ["RAG", "Enterprise", "Long Context"],
        },
    },
    {
        "model_id": "cohere/command-r-08-2024",
        "display_name": "Command R",
        "provider": "openrouter",
        "family": "cohere",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.15,
        "output_cost_per_million": 0.6,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 230,
        "is_featured": True,
        "display_order": 230,
        "categories": ["budget", "large_context"],
        "short_description": "Efficient model for RAG",
        "model_metadata": {
            "description": "Cost-effective for retrieval tasks",
            "good_for": ["RAG", "Search", "Budget"],
        },
    },
    # ====================
    # VISION SPECIALIZED MODELS
    # ====================
    {
        "model_id": "qwen/qwen-2.5-vl-72b-instruct",
        "display_name": "Qwen 2.5 VL 72B",
        "provider": "openrouter",
        "family": "qwen",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 32000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.4,
        "output_cost_per_million": 0.4,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 240,
        "is_featured": True,
        "display_order": 240,
        "categories": ["vision", "budget"],
        "short_description": "Strong vision at low cost",
        "model_metadata": {
            "description": "Qwen's vision-language model",
            "good_for": ["Image Analysis", "Vision Tasks", "Multimodal"],
        },
    },
    {
        "model_id": "meta-llama/llama-3.2-90b-vision-instruct",
        "display_name": "Llama 3.2 90B Vision",
        "provider": "openrouter",
        "family": "meta",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.9,
        "output_cost_per_million": 0.9,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 250,
        "is_featured": True,
        "display_order": 250,
        "categories": ["vision"],
        "short_description": "Open multimodal model",
        "model_metadata": {
            "description": "Meta's vision-capable Llama",
            "good_for": ["Image Understanding", "Multimodal", "Open Source"],
        },
    },
    # ====================
    # ADDITIONAL BUDGET MODELS
    # ====================
    {
        "model_id": "google/gemma-2-27b-it",
        "display_name": "Gemma 2 27B",
        "provider": "openrouter",
        "family": "google",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.27,
        "output_cost_per_million": 0.27,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 260,
        "is_featured": True,
        "display_order": 260,
        "categories": ["fast", "budget"],
        "short_description": "Google's efficient open model",
        "model_metadata": {
            "description": "Lightweight Google model",
            "good_for": ["Simple Tasks", "Budget", "Fast"],
        },
    },
    {
        "model_id": "microsoft/phi-4",
        "display_name": "Phi-4",
        "provider": "openrouter",
        "family": "microsoft",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 16000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.07,
        "output_cost_per_million": 0.14,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 270,
        "is_featured": True,
        "display_order": 270,
        "categories": ["fast", "budget", "code"],
        "short_description": "Small model punching above its weight",
        "model_metadata": {
            "description": "Microsoft's efficient small model",
            "good_for": ["Quick Tasks", "Coding", "Budget"],
        },
    },
    # ====================
    # AMAZON/NVIDIA MODELS
    # ====================
    {
        "model_id": "amazon/nova-pro-v1",
        "display_name": "Amazon Nova Pro",
        "provider": "openrouter",
        "family": "amazon",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 300000,
        "max_output_tokens": 5000,
        "input_cost_per_million": 0.8,
        "output_cost_per_million": 3.2,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 280,
        "is_featured": True,
        "display_order": 280,
        "categories": ["vision", "large_context"],
        "short_description": "Amazon's capable multimodal model",
        "model_metadata": {
            "description": "AWS-native multimodal model",
            "good_for": ["Vision", "Long Context", "Enterprise"],
        },
    },
    {
        "model_id": "nvidia/llama-3.1-nemotron-70b-instruct",
        "display_name": "Nemotron 70B",
        "provider": "openrouter",
        "family": "nvidia",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.12,
        "output_cost_per_million": 0.3,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 290,
        "is_featured": True,
        "display_order": 290,
        "categories": ["code", "budget"],
        "short_description": "NVIDIA-tuned Llama variant",
        "model_metadata": {
            "description": "NVIDIA's optimized Llama model",
            "good_for": ["Coding", "General Tasks", "Budget"],
        },
    },
    # ====================
    # USER API KEY MODELS (BYOK)
    # These are shown in the "Your Keys" tab
    # ====================
    {
        "model_id": "anthropic-direct/claude-sonnet-4.5",
        "display_name": "Claude Sonnet 4.5 (Direct)",
        "provider": "anthropic",
        "family": "anthropic",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 15.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 1000,
        "model_metadata": {
            "description": "Claude Sonnet via your Anthropic API key",
            "good_for": ["Coding", "Analysis", "Agentic Tasks"],
        },
    },
    {
        "model_id": "anthropic-direct/claude-opus-4.5",
        "display_name": "Claude Opus 4.5 (Direct)",
        "provider": "anthropic",
        "family": "anthropic",
        "cost_tier": "premium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 15.0,
        "output_cost_per_million": 75.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 1010,
        "model_metadata": {
            "description": "Claude Opus via your Anthropic API key",
            "good_for": ["Complex Coding", "Architecture", "Deep Analysis"],
        },
    },
    {
        "model_id": "anthropic-direct/claude-haiku-4.5",
        "display_name": "Claude Haiku 4.5 (Direct)",
        "provider": "anthropic",
        "family": "anthropic",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.80,
        "output_cost_per_million": 4.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 1015,
        "model_metadata": {
            "description": "Claude Haiku via your Anthropic API key",
            "good_for": ["Fast Tasks", "Lightweight Coding", "Quick Analysis"],
        },
    },
    {
        "model_id": "openai-direct/gpt-4o",
        "display_name": "GPT-4o (Direct)",
        "provider": "openai",
        "family": "openai",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 2.5,
        "output_cost_per_million": 10.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 1020,
        "model_metadata": {
            "description": "GPT-4o via your OpenAI API key",
            "good_for": ["Multimodal", "Coding", "Vision"],
        },
    },
    {
        "model_id": "google-direct/gemini-2.0-flash",
        "display_name": "Gemini 2.0 Flash (Direct)",
        "provider": "google",
        "family": "google",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.1,
        "output_cost_per_million": 0.4,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 1030,
        "model_metadata": {
            "description": "Gemini Flash via your Google API key",
            "good_for": ["Fast Tasks", "Long Context", "Multimodal"],
        },
    },
]
