"""Default LLM models seed data."""

DEFAULT_MODELS = [
    # Anthropic Claude Models (Vertex AI)
    {
        "model_id": "claude-opus-4-5-20251101",
        "display_name": "Claude Opus 4.5",
        "provider": "vertex",
        "family": "anthropic",
        "cost_tier": "premium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 15.0,  # $15 per million tokens
        "output_cost_per_million": 75.0,  # $75 per million tokens
        "is_enabled": True,
        "is_default": False,  # Only one platform default - using Sonnet 4.5
        "sort_order": 10,
        "model_metadata": {
            "description": "Most capable model for complex reasoning and analysis",
            "good_for": ["Complex Coding", "Architecture", "Deep Analysis", "Vision Tasks"],
        },
    },
    {
        "model_id": "claude-sonnet-4-5-20250929",
        "display_name": "Claude Sonnet 4.5",
        "provider": "vertex",
        "family": "anthropic",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 15.0,
        "is_enabled": True,
        "is_default": True,  # Platform default - best balance of speed/quality/cost
        "sort_order": 20,
        "model_metadata": {
            "description": "Best balance of speed, quality, and cost for most tasks",
            "good_for": ["Coding", "Agentic Tasks", "Fast Analysis"],
        },
    },
    {
        "model_id": "claude-sonnet-4-20250514",
        "display_name": "Claude Sonnet 4",
        "provider": "vertex",
        "family": "anthropic",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "thinking_coming_soon": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 15.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 25,
        "model_metadata": {
            "description": "Reliable model for everyday coding tasks",
            "good_for": ["Balanced Tasks", "Code Review", "Analysis"],
        },
    },
    {
        "model_id": "claude-haiku-4-5-20251001",
        "display_name": "Claude Haiku 4.5",
        "provider": "vertex",
        "family": "anthropic",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.8,
        "output_cost_per_million": 4.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 30,
        "model_metadata": {
            "description": "Fast and efficient for simple tasks",
            "good_for": ["Quick Tasks", "Chat", "Efficient Agents"],
        },
    },
    {
        "model_id": "claude-3-5-haiku-20241022",
        "display_name": "Claude 3.5 Haiku",
        "provider": "vertex",
        "family": "anthropic",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.8,
        "output_cost_per_million": 4.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 35,
        "model_metadata": {
            "description": "Budget option for high-volume simple tasks (no vision)",
            "good_for": ["Fast Coding", "Quick Responses", "Cost-Effective"],
        },
    },
    # Google Gemini Models (Vertex AI Native)
    {
        "model_id": "gemini-2.0-flash",
        "display_name": "Gemini 2.0 Flash",
        "provider": "vertex",
        "family": "google",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.1,
        "output_cost_per_million": 0.4,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 40,
        "model_metadata": {
            "description": "Google's latest fast model with thinking",
            "good_for": ["Fast Tasks", "Multimodal", "Long Context"],
        },
    },
    {
        "model_id": "gemini-2.5-pro-preview",
        "display_name": "Gemini 2.5 Pro",
        "provider": "vertex",
        "family": "google",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 1000000,
        "max_output_tokens": 65536,
        "input_cost_per_million": 1.25,
        "output_cost_per_million": 10.0,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 45,
        "model_metadata": {
            "description": "Google's flagship model for complex tasks",
            "good_for": ["Complex Reasoning", "Long Context", "Multimodal"],
        },
    },
    # Llama Models (Vertex AI Model Garden)
    {
        "model_id": "llama-3.1-70b-instruct",
        "display_name": "Llama 3.1 70B",
        "provider": "vertex",
        "family": "llama",
        "cost_tier": "medium",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 2.65,
        "output_cost_per_million": 3.5,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 50,
        "model_metadata": {
            "description": "Large open-source model for general tasks",
            "good_for": ["Open Source", "General Tasks", "Cost-Effective"],
        },
    },
    {
        "model_id": "llama-3.1-8b-instruct",
        "display_name": "Llama 3.1 8B",
        "provider": "vertex",
        "family": "llama",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 0.3,
        "output_cost_per_million": 0.6,
        "is_enabled": True,
        "is_default": False,
        "sort_order": 55,
        "model_metadata": {
            "description": "Small efficient open-source model",
            "good_for": ["Fast Tasks", "Local Development", "Budget"],
        },
    },
    # ====================
    # User API Key Models (is_user_key_model=True)
    # These models are available when users provide their own API keys
    # ====================
    # Anthropic Direct API Models
    {
        "model_id": "claude-opus-4-5-20251101-anthropic",
        "display_name": "Claude Opus 4.5 (Direct)",
        "provider": "anthropic",
        "family": "anthropic",
        "cost_tier": "premium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 15.0,
        "output_cost_per_million": 75.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 100,
        "model_metadata": {
            "description": "Most capable model via your Anthropic API key",
            "good_for": ["Complex Coding", "Architecture", "Deep Analysis"],
        },
    },
    {
        "model_id": "claude-sonnet-4-5-20250929-anthropic",
        "display_name": "Claude Sonnet 4.5 (Direct)",
        "provider": "anthropic",
        "family": "anthropic",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 3.0,
        "output_cost_per_million": 15.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 110,
        "model_metadata": {
            "description": "Best balance of speed and quality via your API key",
            "good_for": ["Coding", "Agentic Tasks", "Fast Analysis"],
        },
    },
    {
        "model_id": "claude-3-5-haiku-20241022-anthropic",
        "display_name": "Claude 3.5 Haiku (Direct)",
        "provider": "anthropic",
        "family": "anthropic",
        "cost_tier": "low",
        "capabilities": {
            "vision": False,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.8,
        "output_cost_per_million": 4.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 120,
        "model_metadata": {
            "description": "Fast and efficient via your API key",
            "good_for": ["Fast Coding", "Quick Responses", "Cost-Effective"],
        },
    },
    # OpenAI Direct API Models
    {
        "model_id": "gpt-4o",
        "display_name": "GPT-4o",
        "provider": "openai",
        "family": "openai",
        "cost_tier": "high",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 2.5,
        "output_cost_per_million": 10.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 200,
        "model_metadata": {
            "description": "OpenAI's most capable model",
            "good_for": ["Multimodal", "Coding", "Vision"],
        },
    },
    {
        "model_id": "gpt-4o-mini",
        "display_name": "GPT-4o Mini",
        "provider": "openai",
        "family": "openai",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_million": 0.15,
        "output_cost_per_million": 0.6,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 210,
        "model_metadata": {
            "description": "Fast and affordable GPT-4 variant",
            "good_for": ["Fast Tasks", "Budget", "Chat"],
        },
    },
    {
        "model_id": "gpt-4-turbo",
        "display_name": "GPT-4 Turbo",
        "provider": "openai",
        "family": "openai",
        "cost_tier": "high",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_million": 10.0,
        "output_cost_per_million": 30.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 220,
        "model_metadata": {
            "description": "Previous flagship with vision",
            "good_for": ["Vision", "Long Context", "Analysis"],
        },
    },
    # Google AI Direct API Models
    {
        "model_id": "gemini-2.0-flash-google",
        "display_name": "Gemini 2.0 Flash",
        "provider": "google",
        "family": "google",
        "cost_tier": "low",
        "capabilities": {
            "vision": True,
            "thinking": True,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 0.1,
        "output_cost_per_million": 0.4,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 300,
        "model_metadata": {
            "description": "Google's latest fast model",
            "good_for": ["Fast Tasks", "Multimodal", "Long Context"],
        },
    },
    {
        "model_id": "gemini-1.5-pro",
        "display_name": "Gemini 1.5 Pro",
        "provider": "google",
        "family": "google",
        "cost_tier": "medium",
        "capabilities": {
            "vision": True,
            "thinking": False,
            "tool_use": True,
            "streaming": True,
            "json_mode": True,
        },
        "context_window": 2000000,
        "max_output_tokens": 8192,
        "input_cost_per_million": 1.25,
        "output_cost_per_million": 5.0,
        "is_enabled": True,
        "is_default": False,
        "is_user_key_model": True,
        "sort_order": 310,
        "model_metadata": {
            "description": "Long context multimodal model",
            "good_for": ["Massive Context", "Video", "Document Analysis"],
        },
    },
]
