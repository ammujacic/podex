"""Default LLM provider seed data.

Stores metadata about LLM providers (Anthropic, OpenAI, Google, Ollama, etc.)
including branding, documentation URLs, and capabilities.
These are synced to the database on startup and can be customized by admins.
"""

from typing import TypedDict


class LLMProviderData(TypedDict, total=False):
    """Type definition for LLM provider seed data."""

    slug: str
    name: str
    description: str | None
    icon: str | None
    color: str | None
    logo_url: str | None
    is_local: bool
    default_url: str | None
    docs_url: str | None
    setup_guide_url: str | None
    requires_api_key: bool
    supports_streaming: bool
    supports_tools: bool
    supports_vision: bool
    is_enabled: bool
    sort_order: int


DEFAULT_PROVIDERS: list[LLMProviderData] = [
    {
        "slug": "anthropic",
        "name": "Anthropic",
        "description": "Claude models - Opus 4.5, Sonnet 4.5, Haiku. Advanced reasoning.",
        "icon": "Brain",
        "color": "#D97757",
        "is_local": False,
        "docs_url": "https://console.anthropic.com/",
        "setup_guide_url": "https://docs.anthropic.com/en/docs/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 10,
    },
    {
        "slug": "openai",
        "name": "OpenAI",
        "description": "GPT-4o, GPT-4 Turbo, o1 models. Industry-leading language models.",
        "icon": "Sparkles",
        "color": "#10A37F",
        "is_local": False,
        "docs_url": "https://platform.openai.com/",
        "setup_guide_url": "https://platform.openai.com/docs/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 20,
    },
    {
        "slug": "google",
        "name": "Google",
        "description": "Gemini 2.0 Flash, Gemini 2.5 Pro. Large context window models.",
        "icon": "Zap",
        "color": "#4285F4",
        "is_local": False,
        "docs_url": "https://ai.google.dev/",
        "setup_guide_url": "https://ai.google.dev/gemini-api/docs/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 30,
    },
    {
        "slug": "ollama",
        "name": "Ollama",
        "description": "Run open-source models locally. Llama, Mistral, CodeLlama, and more.",
        "icon": "Server",
        "color": "#FFFFFF",
        "is_local": True,
        "default_url": "http://localhost:11434",
        "docs_url": "https://ollama.ai/",
        "setup_guide_url": "https://github.com/ollama/ollama#readme",
        "requires_api_key": False,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 40,
    },
    {
        "slug": "deepseek",
        "name": "DeepSeek",
        "description": "DeepSeek-V3 and DeepSeek-Coder. High-performance coding models.",
        "icon": "Code2",
        "color": "#6366F1",
        "is_local": False,
        "docs_url": "https://platform.deepseek.com/",
        "setup_guide_url": "https://platform.deepseek.com/api-docs/",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": False,
        "is_enabled": True,
        "sort_order": 50,
    },
    {
        "slug": "groq",
        "name": "Groq",
        "description": "Ultra-fast inference with Groq LPUs. Llama and Mixtral models.",
        "icon": "Gauge",
        "color": "#F55036",
        "is_local": False,
        "docs_url": "https://console.groq.com/",
        "setup_guide_url": "https://console.groq.com/docs/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": False,
        "is_enabled": True,
        "sort_order": 60,
    },
    {
        "slug": "together",
        "name": "Together AI",
        "description": "Access to 100+ open-source models. Fast inference and fine-tuning.",
        "icon": "Users",
        "color": "#0066FF",
        "is_local": False,
        "docs_url": "https://www.together.ai/",
        "setup_guide_url": "https://docs.together.ai/docs/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 70,
    },
    {
        "slug": "fireworks",
        "name": "Fireworks AI",
        "description": "High-speed inference for open models. Optimized for production.",
        "icon": "Flame",
        "color": "#FF6B35",
        "is_local": False,
        "docs_url": "https://fireworks.ai/",
        "setup_guide_url": "https://docs.fireworks.ai/getting-started/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 80,
    },
    {
        "slug": "mistral",
        "name": "Mistral AI",
        "description": "Mistral Large, Medium, and Small. European AI models.",
        "icon": "Wind",
        "color": "#FF7000",
        "is_local": False,
        "docs_url": "https://mistral.ai/",
        "setup_guide_url": "https://docs.mistral.ai/getting-started/quickstart/",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 90,
    },
    {
        "slug": "openrouter",
        "name": "OpenRouter",
        "description": "Unified API for 100+ models. Route requests to the best provider.",
        "icon": "GitBranch",
        "color": "#6B46C1",
        "is_local": False,
        "docs_url": "https://openrouter.ai/",
        "setup_guide_url": "https://openrouter.ai/docs",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 100,
    },
    {
        "slug": "azure",
        "name": "Azure OpenAI",
        "description": "Enterprise-grade OpenAI models on Microsoft Azure.",
        "icon": "Cloud",
        "color": "#0078D4",
        "is_local": False,
        "docs_url": "https://azure.microsoft.com/en-us/products/ai-services/openai-service",
        "setup_guide_url": "https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 110,
    },
    {
        "slug": "aws-bedrock",
        "name": "AWS Bedrock",
        "description": "Managed AI models on AWS. Claude, Llama, and more.",
        "icon": "Database",
        "color": "#FF9900",
        "is_local": False,
        "docs_url": "https://aws.amazon.com/bedrock/",
        "setup_guide_url": "https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 120,
    },
    {
        "slug": "vertex",
        "name": "Google Vertex AI",
        "description": "Enterprise AI on Google Cloud. Claude, Gemini, and PaLM models.",
        "icon": "Layers",
        "color": "#34A853",
        "is_local": False,
        "docs_url": "https://cloud.google.com/vertex-ai",
        "setup_guide_url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform",
        "requires_api_key": True,
        "supports_streaming": True,
        "supports_tools": True,
        "supports_vision": True,
        "is_enabled": True,
        "sort_order": 130,
    },
]
