# ===========================================
# Podex Development Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values

# ===========================================
# LLM Provider Configuration
# ===========================================
# Set LLM_PROVIDER to choose your backend:
#   - "anthropic" (default) - requires ANTHROPIC_API_KEY
#   - "openai" - requires OPENAI_API_KEY
#   - "ollama" - free local models, no API key needed
#   - "bedrock" - AWS Bedrock, requires AWS credentials

LLM_PROVIDER=ollama

# Ollama (recommended for local development - FREE)
# Install: https://ollama.ai then run: ollama pull qwen2.5-coder:14b
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5-coder:14b

# Cloud API Keys (only needed if using cloud providers)
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# Database (auto-configured for local development)
DATABASE_URL=postgresql+asyncpg://dev:devpass@localhost:5432/podex

# Redis (auto-configured for local development)
REDIS_URL=redis://localhost:6379

# AWS (LocalStack for local development)
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
AWS_ENDPOINT=http://localhost:4566

# JWT Secret (change in production!)
JWT_SECRET_KEY=dev-secret-key-change-in-production

# Workspace Configuration
WORKSPACE_BASE_PATH=/tmp/podex/workspaces

# Tool Execution Limits
COMMAND_TIMEOUT=60
MAX_FILE_SIZE=1000000
MAX_SEARCH_RESULTS=50

# Optional: GitHub OAuth (for production auth)
# GITHUB_CLIENT_ID=
# GITHUB_CLIENT_SECRET=

# Optional: Google OAuth (for production auth)
# GOOGLE_CLIENT_ID=
# GOOGLE_CLIENT_SECRET=

# ===========================================
# Service URLs (for inter-service communication)
# ===========================================
COMPUTE_SERVICE_URL=http://compute:3003
COMPUTE_INTERNAL_API_KEY=${INTERNAL_API_KEY}
AGENT_SERVICE_URL=http://agent:3002

# Agent task settings
AGENT_TASK_POLL_INTERVAL=0.5
AGENT_TASK_TIMEOUT=120.0

# ===========================================
# Voice/Audio Settings (AWS Polly & Transcribe)
# ===========================================
DEFAULT_POLLY_VOICE_ID=Joanna
DEFAULT_POLLY_ENGINE=neural
DEFAULT_TRANSCRIBE_LANGUAGE=en-US
VOICE_AUDIO_S3_PREFIX=audio/voice

# ===========================================
# Compute Service Settings
# ===========================================
# Use "docker" for local, "aws" for production
COMPUTE_MODE=docker
COMPUTE_DOCKER_NETWORK=podex-dev
COMPUTE_WARM_POOL_SIZE=2
COMPUTE_MAX_WORKSPACES=10
COMPUTE_WORKSPACE_TIMEOUT=3600

# S3 Storage (shared across services)
S3_BUCKET=podex-workspaces
S3_WORKSPACE_PREFIX=workspaces

# Compute-specific S3 settings (with COMPUTE_ prefix)
COMPUTE_S3_BUCKET=podex-workspaces
COMPUTE_S3_PREFIX=workspaces
COMPUTE_S3_SYNC_INTERVAL=30

# ===========================================
# Internal Service Authentication
# ===========================================
# Shared key for secure inter-service communication
# IMPORTANT: Change this in production!
INTERNAL_API_KEY=dev-internal-key

# ===========================================
# Cache Settings (API Service)
# ===========================================
CACHE_TTL_TEMPLATES=3600
CACHE_TTL_SESSIONS=300
CACHE_TTL_USER_CONFIG=600
CACHE_PREFIX=podex:cache:

# ===========================================
# Context and Memory Settings
# ===========================================
MAX_CONTEXT_TOKENS=100000
CONTEXT_SUMMARIZATION_THRESHOLD=40
CONTEXT_TOKEN_THRESHOLD=50000

# ===========================================
# Sentry Error Tracking & Monitoring
# ===========================================
# Get your DSN from https://sentry.io
# All services share the same DSN but use different projects/environments

# Backend Services DSN
SENTRY_DSN=

# Frontend DSN (public, safe to expose)
NEXT_PUBLIC_SENTRY_DSN=

# Environment name (development, staging, production)
NEXT_PUBLIC_ENVIRONMENT=development

# Performance monitoring sample rates (0.0 to 1.0)
# In production, use lower values like 0.1-0.2 to reduce costs
SENTRY_TRACES_SAMPLE_RATE=1.0
SENTRY_PROFILES_SAMPLE_RATE=1.0

# Optional: Release version for tracking deployments
# NEXT_PUBLIC_SENTRY_RELEASE=podex@0.1.0

# Optional: Enable debug mode for development
# SENTRY_DEBUG=true

# Optional: Sentry organization and project for source map uploads (CI/CD only)
# SENTRY_ORG=your-org
# SENTRY_PROJECT=podex-web
# SENTRY_AUTH_TOKEN=your-auth-token

# ===========================================
# MCP (Model Context Protocol) Configuration
# ===========================================
# Enable specific MCP servers by slug (comma-separated)
# Available: filesystem,git,github,fetch,memory,brave-search,puppeteer,slack,postgres,sqlite,docker,kubernetes
MCP_ENABLED_SERVERS=
MCP_AUTO_DISCOVER=true

# MCP connection settings
MCP_CONNECTION_TIMEOUT=30
MCP_TOOL_TIMEOUT=60
MCP_MAX_RETRIES=3
MCP_RETRY_DELAY=1.0

# Per-server secrets (optional - users can also configure via UI)
# MCP_GITHUB_TOKEN=your-github-token
# MCP_BRAVE_API_KEY=your-brave-api-key
# MCP_SLACK_BOT_TOKEN=your-slack-bot-token
# MCP_SLACK_TEAM_ID=your-slack-team-id
# MCP_POSTGRES_CONNECTION_STRING=postgresql://user:pass@host:5432/db

# ===========================================
# Task Queue Settings (Agent Service)
# ===========================================
TASK_QUEUE_POLL_INTERVAL=1.0
TASK_TTL=86400
TASK_MAX_RETRIES=3
